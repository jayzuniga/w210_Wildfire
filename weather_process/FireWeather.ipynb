{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Station metadata:\n",
    "\n",
    "   - name, ID, stid: identifiers for the weather station\n",
    "   - elevation, latitude, longitude: location of the weather station\n",
    "\n",
    "Observations:\n",
    "\n",
    "   - date_time\n",
    "   - air_temp (Celcius)\n",
    "   - precip_accum (millimeters)\n",
    "   - relative_humidity (%)\n",
    "   - wind_speed (m/s)\n",
    "   - wind_gust (m/s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from dateutil import rrule\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from urllib.request import urlopen\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = \"E:/GitHub/w210_Wildfire/data/export/\"\n",
    "baseurl = \"https://api.synopticdata.com/v2/stations/timeseries?state=ca&vars=air_temp,wind_speed,wind_gust,pressure,relative_humidity,precip_accum&token=3126cda0bfe5490f91911a15826bbf3b\"\n",
    "obsvars = ['NAME', 'ID', 'STID', 'ELEVATION', 'LATITUDE', 'LONGITUDE',\n",
    "           'OBSERVATIONS.date_time', 'OBSERVATIONS.air_temp_set_1', 'OBSERVATIONS.precip_accum_set_1', \n",
    "           'OBSERVATIONS.relative_humidity_set_1', 'OBSERVATIONS.wind_speed_set_1','OBSERVATIONS.wind_gust_set_1']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataurl = \"https://api.synopticdata.com/v2/stations/metadata?state=ca&status=active&start=201601010000&end=201812310000&token=3126cda0bfe5490f91911a15826bbf3b\"\n",
    "response = urlopen(metadataurl)\n",
    "json_meta_data = response.read().decode('utf-8', 'replace')\n",
    "metadata = json.loads(json_meta_data)\n",
    "station_metadata = json_normalize(metadata['STATION'])\n",
    "stationids = station_metadata['STID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     KBIH\n",
       "6     KBLH\n",
       "7     KBLU\n",
       "8     KBUR\n",
       "9     KBYS\n",
       "10    KCCR\n",
       "11    KCEC\n",
       "Name: STID, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stationids[5:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract observations from single station JSON and return daily summary data\n",
    "\n",
    "def extract_observations(obs):\n",
    "    cols = list(obs.columns)\n",
    "    obs = obs.iloc[0]\n",
    "    date_time = obs['OBSERVATIONS.date_time']\n",
    "    date = [pd.to_datetime(d).date() for d in date_time]\n",
    "    dtlen = len(date_time)\n",
    "    fake = [np.NaN]*dtlen\n",
    "    \n",
    "    # Extract the observations if the columns exist\n",
    "    air_temp = fake if 'OBSERVATIONS.air_temp_set_1' not in cols else list(np.float_(obs['OBSERVATIONS.air_temp_set_1']))                                                                   \n",
    "    precip_accum = fake if 'OBSERVATIONS.precip_accum_set_1' not in cols else list(np.float_(obs['OBSERVATIONS.precip_accum_set_1']))\n",
    "    relative_humidity = fake if 'OBSERVATIONS.relative_humidity_set_1' not in cols else list(np.float_(obs['OBSERVATIONS.relative_humidity_set_1']))\n",
    "    wind_speed = fake if 'OBSERVATIONS.wind_speed_set_1' not in cols else list(np.float_(obs['OBSERVATIONS.wind_speed_set_1']))\n",
    "    wind_gust = fake if 'OBSERVATIONS.wind_gust_set_1' not in cols else list(np.float_(obs['OBSERVATIONS.wind_gust_set_1']))\n",
    "\n",
    "    # Create a dataframe with the observations and date\n",
    "    full_obs_df = pd.DataFrame(np.column_stack([date, air_temp, precip_accum, relative_humidity, wind_speed, wind_gust]),\n",
    "                          columns=['date', 'air_temp', 'precip_accum', 'relative_humidity', 'wind_speed', 'wind_gust'])\n",
    "    full_obs_df[['air_temp', 'precip_accum', 'relative_humidity', 'wind_speed', 'wind_gust']] = full_obs_df[['air_temp', 'precip_accum', 'relative_humidity', 'wind_speed', 'wind_gust']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Group by date and create daily summary features\n",
    "    obs_df = full_obs_df.groupby('date', as_index=False).agg({'air_temp':['max', 'min', 'mean'], 'precip_accum':'max', \n",
    "                                            'relative_humidity':['max', 'min', 'mean'],\n",
    "                                            'wind_speed':['max', 'min', 'mean'], 'wind_gust':'max',})\n",
    "    obs_df.columns = [\"_\".join(x) for x in obs_df.columns.ravel()]\n",
    "    \n",
    "    # Add station metadata\n",
    "    obs_df['name'] = obs['NAME']\n",
    "    obs_df['ID'] = obs['ID']\n",
    "    obs_df['stid'] = obs['STID']\n",
    "    obs_df['elevation'] = np.float_(obs['ELEVATION'])\n",
    "    obs_df['latitude'] = np.float_(obs['LATITUDE'])\n",
    "    obs_df['longitude'] = np.float_(obs['LONGITUDE'])\n",
    "    \n",
    "    return obs_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry connection: AV447\n",
      "Retry connection: PG115\n",
      "Retry connection: SE082\n",
      "Retry connection: F3842\n",
      "Retry connection: SE095\n",
      "Retry connection: PG148\n",
      "Retry connection: PG164\n",
      "Retry connection: F4319\n",
      "Retry connection: F4326\n",
      "Retry connection: PG202\n",
      "Retry connection: XOMC1\n",
      "Retry connection: SFEC1\n",
      "Retry connection: TCICA\n",
      "Retry connection: PG218\n",
      "Retry connection: PG244\n",
      "Retry connection: SE177\n",
      "Retry connection: PG278\n",
      "Retry connection: SE195\n",
      "Retry connection: PG253\n",
      "Retry connection: SE196\n",
      "Retry connection: SE198\n",
      "Retry connection: DLLC1\n",
      "Retry connection: PG334\n",
      "Retry connection: SE232\n",
      "Retry connection: PG340\n",
      "Retry connection: PG325\n",
      "Retry connection: PG333\n",
      "Retry connection: F5340\n",
      "Retry connection: PG324\n",
      "Retry connection: A2722\n",
      "Retry connection: A3581\n",
      "Retry connection: PG354\n",
      "Retry connection: PG328\n",
      "No data for SE264 on 201609010000\n",
      "No data for SE265 on 201609010000\n",
      "No data for SE266 on 201609010000\n",
      "No data for PG376 on 201609010000\n",
      "Retry connection: PG395\n",
      "Retry connection: SE287\n",
      "Retry connection: SE293\n",
      "Retry connection: PG397\n",
      "Retry connection: SE297\n",
      "No data for SE299 on 201609010000\n",
      "Retry connection: SE309\n",
      "Retry connection: SE315\n",
      "No data for LIB08 on 201609010000\n",
      "No data for SE318 on 201609010000\n",
      "No data for PG425 on 201609010000\n",
      "No data for PG428 on 201609010000\n",
      "No data for SE327 on 201609010000\n",
      "No data for F5632 on 201609010000\n",
      "No data for PG433 on 201609010000\n",
      "No data for SE335 on 201609010000\n",
      "No data for SE339 on 201609010000\n",
      "No data for PC001 on 201609010000\n",
      "No data for SE345 on 201609010000\n",
      "No data for SE346 on 201609010000\n"
     ]
    }
   ],
   "source": [
    "strstart = \"201609010000\"\n",
    "strend = \"201612312359\"\n",
    "\n",
    "weather = pd.DataFrame()\n",
    "\n",
    "for stid in stationids[4000:5000]:    \n",
    "    \n",
    "    # API call for stationid using start and end day\n",
    "    url = baseurl + \"&stid=\" + stid + \"&start=\" + strstart + \"&end=\" + strend\n",
    "#    try:\n",
    "#        response = urlopen(url)\n",
    "#    except:\n",
    "#        time.sleep(5)\n",
    "#        response = urlopen(url)\n",
    "\n",
    "    for attempt in range(10):\n",
    "        try:\n",
    "            response = urlopen(url)\n",
    "        except:\n",
    "            print(\"Retry connection: \" + stid)\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        print(\"Failed connection: \" + stid)\n",
    "\n",
    "    json_data = response.read().decode('utf-8', 'replace')\n",
    "    data = json.loads(json_data)\n",
    "        \n",
    "    # obtain station observations from JSON and append to data frame\n",
    "    try:\n",
    "        station = json_normalize(data['STATION'], errors='ignore')\n",
    "    except:\n",
    "        print(\"No data for \" + stid + \" on \" + strstart)\n",
    "    else:\n",
    "        if not station.empty:\n",
    "            observations = extract_observations(station)\n",
    "            # dump station data to csv\n",
    "            filename = strstart + \"_\" + stid + \".csv\"\n",
    "            observations.to_csv(outputPath + filename, header=True, index=False)\n",
    "            weather = weather.append(observations, ignore_index = True)\n",
    "\n",
    "# full dump of annual weather data\n",
    "filename = strstart + \"_all\" + \".csv\"\n",
    "weather.to_csv(outputPath + filename, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BGPC1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stationids[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4778"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stationids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
