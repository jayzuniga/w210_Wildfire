{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Station metadata:\n",
    "\n",
    "   - name, ID, stid: identifiers for the weather station\n",
    "   - elevation, latitude, longitude: location of the weather station\n",
    "\n",
    "Observations:\n",
    "\n",
    "   - date_time\n",
    "   - air_temp (Celcius)\n",
    "   - precip_accum (millimeters)\n",
    "   - relative_humidity (%)\n",
    "   - wind_speed (m/s)\n",
    "   - wind_gust (m/s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import datetime\n",
    "from dateutil import rrule\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from urllib.request import urlopen\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = \"E:/GitHub/w210_Wildfire/data/\"\n",
    "baseurl = \"https://api.synopticdata.com/v2/stations/timeseries?state=ca&vars=air_temp,wind_speed,wind_gust,pressure,relative_humidity,precip_accum&token=3126cda0bfe5490f91911a15826bbf3b\"\n",
    "obsvars = ['NAME', 'ID', 'STID', 'ELEVATION', 'LATITUDE', 'LONGITUDE',\n",
    "           'OBSERVATIONS.date_time', 'OBSERVATIONS.air_temp_set_1', 'OBSERVATIONS.precip_accum_set_1', \n",
    "           'OBSERVATIONS.relative_humidity_set_1', 'OBSERVATIONS.wind_speed_set_1','OBSERVATIONS.wind_gust_set_1']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataurl = \"https://api.synopticdata.com/v2/stations/metadata?state=ca&status=active&start=201601010000&end=201812310000&token=3126cda0bfe5490f91911a15826bbf3b\"\n",
    "response = urlopen(metadataurl)\n",
    "json_meta_data = response.read().decode('utf-8', 'replace')\n",
    "metadata = json.loads(json_meta_data)\n",
    "station_metadata = json_normalize(metadata['STATION'])\n",
    "stationids = station_metadata['STID']\n",
    "#stationids[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract observations from single station JSON and return daily summary data\n",
    "\n",
    "def extract_observations(obs):\n",
    "    cols = list(obs.columns)\n",
    "    obs = obs.iloc[0]\n",
    "    date_time = obs['OBSERVATIONS.date_time']\n",
    "    date = [pd.to_datetime(d).date() for d in date_time]\n",
    "    dtlen = len(date_time)\n",
    "    fake = [np.NaN]*dtlen\n",
    "    \n",
    "    # Extract the observations if the columns exist\n",
    "    air_temp = fake if 'OBSERVATIONS.air_temp_set_1' not in cols else list(np.float_(obs['OBSERVATIONS.air_temp_set_1']))                                                                   \n",
    "    precip_accum = fake if 'OBSERVATIONS.precip_accum_set_1' not in cols else list(np.float_(obs['OBSERVATIONS.precip_accum_set_1']))\n",
    "    relative_humidity = fake if 'OBSERVATIONS.relative_humidity_set_1' not in cols else list(np.float_(obs['OBSERVATIONS.relative_humidity_set_1']))\n",
    "    wind_speed = fake if 'OBSERVATIONS.wind_speed_set_1' not in cols else list(np.float_(obs['OBSERVATIONS.wind_speed_set_1']))\n",
    "    wind_gust = fake if 'OBSERVATIONS.wind_gust_set_1' not in cols else list(np.float_(obs['OBSERVATIONS.wind_gust_set_1']))\n",
    "\n",
    "    # Create a dataframe with the observations and date\n",
    "    full_obs_df = pd.DataFrame(np.column_stack([date, air_temp, precip_accum, relative_humidity, wind_speed, wind_gust]),\n",
    "                          columns=['date', 'air_temp', 'precip_accum', 'relative_humidity', 'wind_speed', 'wind_gust'])\n",
    "    full_obs_df[['air_temp', 'precip_accum', 'relative_humidity', 'wind_speed', 'wind_gust']] = full_obs_df[['air_temp', 'precip_accum', 'relative_humidity', 'wind_speed', 'wind_gust']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Group by date and create daily summary features\n",
    "    obs_df = full_obs_df.groupby('date', as_index=False).agg({'air_temp':['max', 'min', 'mean'], 'precip_accum':'max', \n",
    "                                            'relative_humidity':['max', 'min', 'mean'],\n",
    "                                            'wind_speed':['max', 'min', 'mean'], 'wind_gust':'max',})\n",
    "    obs_df.columns = [\"_\".join(x) for x in obs_df.columns.ravel()]\n",
    "    \n",
    "    # Add station metadata\n",
    "    obs_df['name'] = obs['NAME']\n",
    "    obs_df['ID'] = obs['ID']\n",
    "    obs_df['stid'] = obs['STID']\n",
    "    obs_df['elevation'] = np.float_(obs['ELEVATION'])\n",
    "    obs_df['latitude'] = np.float_(obs['LATITUDE'])\n",
    "    obs_df['longitude'] = np.float_(obs['LONGITUDE'])\n",
    "    \n",
    "    return obs_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for PBUC1 on 201801010000\n",
      "No data for PUR69 on 201801010000\n",
      "No data for PUR91 on 201801010000\n",
      "No data for PUR92 on 201801010000\n",
      "No data for PG319 on 201801010000\n",
      "No data for A3610 on 201801010000\n",
      "No data for SE264 on 201801010000\n",
      "No data for SE265 on 201801010000\n",
      "No data for SE266 on 201801010000\n",
      "No data for PG366 on 201801010000\n",
      "No data for PG376 on 201801010000\n",
      "No data for PG393 on 201801010000\n",
      "No data for SE299 on 201801010000\n",
      "No data for SE313 on 201801010000\n",
      "No data for LIB04 on 201801010000\n",
      "No data for LIB06 on 201801010000\n",
      "No data for SE316 on 201801010000\n",
      "No data for SE317 on 201801010000\n",
      "No data for PG432 on 201801010000\n",
      "No data for PG426 on 201801010000\n",
      "No data for SE318 on 201801010000\n",
      "No data for SE321 on 201801010000\n",
      "No data for SE322 on 201801010000\n",
      "No data for PG423 on 201801010000\n",
      "No data for P042C on 201801010000\n",
      "No data for PG425 on 201801010000\n",
      "No data for PG428 on 201801010000\n",
      "No data for SE323 on 201801010000\n",
      "No data for SE324 on 201801010000\n",
      "No data for SE325 on 201801010000\n",
      "No data for SE326 on 201801010000\n",
      "No data for F1136 on 201801010000\n",
      "No data for SE328 on 201801010000\n",
      "No data for F5632 on 201801010000\n",
      "No data for F5661 on 201801010000\n",
      "No data for F5669 on 201801010000\n",
      "No data for LIB09 on 201801010000\n",
      "No data for PG431 on 201801010000\n",
      "No data for PG415 on 201801010000\n",
      "No data for SE330 on 201801010000\n",
      "No data for SE332 on 201801010000\n",
      "No data for SE334 on 201801010000\n",
      "No data for PG433 on 201801010000\n",
      "No data for SE335 on 201801010000\n",
      "No data for PG429 on 201801010000\n",
      "No data for SE337 on 201801010000\n",
      "No data for SE338 on 201801010000\n",
      "No data for SE340 on 201801010000\n",
      "No data for E8841 on 201801010000\n",
      "No data for SE342 on 201801010000\n",
      "No data for PG462 on 201801010000\n",
      "No data for PC001 on 201801010000\n",
      "No data for PG427 on 201801010000\n",
      "No data for PG458 on 201801010000\n",
      "No data for F5690 on 201801010000\n",
      "No data for SE344 on 201801010000\n"
     ]
    }
   ],
   "source": [
    "strstart = \"201801010000\"\n",
    "strend = \"201806302359\"\n",
    "\n",
    "weather = pd.DataFrame()\n",
    "\n",
    "for stid in stationids:\n",
    "    # API call for stationid using start and end day\n",
    "    url = baseurl + \"&stid=\" + stid + \"&start=\" + strstart + \"&end=\" + strend\n",
    "    response = urlopen(url)\n",
    "    json_data = response.read().decode('utf-8', 'replace')\n",
    "    data = json.loads(json_data)\n",
    "        \n",
    "    # obtain station observations from JSON and append to data frame\n",
    "    try:\n",
    "        station = json_normalize(data['STATION'], errors='ignore')\n",
    "    except:\n",
    "        print(\"No data for \" + stid + \" on \" + strstart)\n",
    "    else:\n",
    "        if not station.empty:\n",
    "            observations = extract_observations(station)\n",
    "            # dump station data to csv\n",
    "            filename = strstart + \"_\" + stid + \".csv\"\n",
    "            observations.to_csv(outputPath + filename, header=True, index=False)\n",
    "            weather = weather.append(observations, ignore_index = True)\n",
    "\n",
    "# full dump of annual weather data\n",
    "filename = strstart + \"_all\" + \".csv\"\n",
    "weather.to_csv(outputPath + filename, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
