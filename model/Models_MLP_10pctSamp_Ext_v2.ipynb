{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.python.keras import metrics\n",
    "\n",
    "from tensorflow.python.keras.layers import Conv1D\n",
    "from tensorflow.python.keras.layers import MaxPooling1D\n",
    "from tensorflow.python.keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.python.keras.layers import GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1244493, 164)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_csv('./consolidated_4_10pct_sample_ext.csv')\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, features):\n",
    "    indexer = data[['s2_cell_id','measure_date']].copy()\n",
    "    train = data[data.measure_date < '2018-01-01'].copy()\n",
    "    test = data[data.measure_date >= '2018-01-01'].copy()\n",
    "    \n",
    "    y_train = train.wf_wildfire.copy().values\n",
    "    y_test = test.wf_wildfire.copy().values    \n",
    "    \n",
    "    y_train_ext = train.wf_wildfire_ext.copy().values\n",
    "    y_test_ext = test.wf_wildfire_ext.copy().values    \n",
    "\n",
    "    train = train[features]\n",
    "    test = test[features]    \n",
    "    \n",
    "    test_ids = data[data.measure_date >= '2018-01-01'][['s2_cell_id', 'measure_date']]\n",
    "    \n",
    "    return train, test, y_train, y_test, y_train_ext, y_test_ext, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Source: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "    Prints and plots the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        y_true: list of true target labels\n",
    "        y_pred: list of predicted target labels\n",
    "        classes: tuple of class labels in 0, 1 order\n",
    "\n",
    "    Kwargs:\n",
    "        normalize: bool, normalize confusion matrix or not\n",
    "        cmap: color map\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        title = 'Normalized confusion matrix'\n",
    "    else:\n",
    "        title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes,\n",
    "           yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(),\n",
    "             rotation=45,\n",
    "             ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_prob(probs, y_test):\n",
    "    y_binned = np.digitize(probs, np.arange(0,1.1,0.1))\n",
    "    bin_df = pd.DataFrame(list(zip(y_test, probs, y_binned)), columns =['Actual', 'Prob', 'Bin'])\n",
    "    bin_df = bin_df.groupby('Bin').agg({'Actual': ['mean', 'sum', 'count'], 'Prob': 'mean'})\n",
    "    return bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/43178668/\n",
    "    record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "    \"\"\"\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(layers, units, dropout_rate, input_shape, op_units, op_activation):\n",
    "    \"\"\"\n",
    "    Creates an instance of a multi-layer perceptron model.\n",
    "\n",
    "    Arguments\n",
    "      layers: int, number of `Dense` layers in the model.\n",
    "      units: int, output dimension of the layers.\n",
    "      dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "      input_shape: tuple, shape of input to the model.\n",
    "      op_units: number of output units (1 for binary target)\n",
    "      op_activation: activation function (sigmoid for binary target)\n",
    "\n",
    "    Returns\n",
    "      An MLP model instance.\n",
    "    \"\"\"\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=op_units, activation=op_activation))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data,\n",
    "                model_type='cnn',\n",
    "                learning_rate=1e-3,\n",
    "                epochs=1000,\n",
    "                batch_size=128,\n",
    "                blocks=2,\n",
    "                filters=64,\n",
    "                layers=2,\n",
    "                units=64,\n",
    "                dropout_rate=0.2,\n",
    "                kernel_size=3,\n",
    "                pool_size=3,\n",
    "                num_classes=2,\n",
    "                class_weights={0:1.,1:1.}):\n",
    "    \"\"\"\n",
    "    Trains sequence model on the given dataset.\n",
    "\n",
    "    Args:\n",
    "      data: tuples of vectorized training and test texts and labels.\n",
    "      log_dir: directory to write logs to\n",
    "\n",
    "    Kwargs:\n",
    "      model_type: str, type of model to train\n",
    "      word_index: word_index if applicable\n",
    "      learning_rate: float, learning rate for training model.\n",
    "      epochs: int, number of epochs.\n",
    "      batch_size: int, number of samples per batch.\n",
    "      blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n",
    "      filters: int, output dimension of sepCNN layers in the model.\n",
    "      dropout_rate: float: percentage of input to drop at Dropout layers.\n",
    "      embedding_dim: int, dimension of the embedding vectors.\n",
    "      kernel_size: int, length of the convolution window.\n",
    "      pool_size: int, factor by which to downscale input at MaxPooling layer.\n",
    "      max_num_words: int, max number of features to use\n",
    "      num_classes: int, number of classes in the target variable\n",
    "      use_pretrained_embedding: bool, use pretrained embeddings or no\n",
    "      is_embedding_trainable: bool, train embeddings or no\n",
    "      use_word_embedding: bool, False if sentence encodding is used\n",
    "      glove_dir: directory with glove embeddings if applicable\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the data.\n",
    "    x_train, train_labels, x_val, val_labels = data\n",
    "\n",
    "    if num_classes == 2:\n",
    "        op_units, op_activation = 1, 'sigmoid'\n",
    "    else:\n",
    "        op_units, op_activation = num_classes, 'softmax'\n",
    "\n",
    "    # Create model instance.\n",
    "    if model_type == 'cnn':\n",
    "        model = cnn_model(filters=filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          layers=layers,\n",
    "                          dropout_rate=dropout_rate,\n",
    "                          pool_size=pool_size,\n",
    "                          input_shape=x_train.shape[1:],\n",
    "                          op_units=op_units,\n",
    "                          op_activation=op_activation)\n",
    "    elif model_type == 'mlp':\n",
    "        model = mlp_model(layers=layers,\n",
    "                          units=units,\n",
    "                          dropout_rate=dropout_rate,\n",
    "                          input_shape=x_train.shape[1:],\n",
    "                          op_units=op_units,\n",
    "                          op_activation=op_activation)\n",
    "\n",
    "    # Compile model with learning parameters.\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(lr=learning_rate) - didn't work (too many false negatives)\n",
    "#     optimizer = tf.keras.optimizers.SGD(lr=learning_rate) - similar performance to Adam\n",
    "#     optimizer = tf.keras.optimizers.Adagrad(lr=learning_rate) - didn't work (too many false positives)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[metrics.Recall()])\n",
    "\n",
    "    # Create callback for early stopping on validation loss. If the loss does\n",
    "    # not decrease in two consecutive tries, stop training.\n",
    "    callbacks = [\n",
    "#           tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "#                                            patience=2),\n",
    "          TimeHistory()]\n",
    "\n",
    "    # Train and validate model.\n",
    "    history = model.fit(\n",
    "      x_train,\n",
    "      train_labels,\n",
    "      epochs=epochs,\n",
    "      callbacks=callbacks,\n",
    "      validation_data=(x_val, val_labels),\n",
    "      verbose=2,  # Logs once per epoch.\n",
    "      batch_size=batch_size,\n",
    "      class_weight=class_weights)\n",
    "\n",
    "    train_pred_probs = model.predict(x_train)\n",
    "    val_pred_probs = model.predict(x_val)\n",
    "\n",
    "    return history.history, model, train_pred_probs, val_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer: Adam; Features: - precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_features = [\n",
    "    'tl_object_id',\n",
    "    'tl_kv_sort_sum'\n",
    "]\n",
    "\n",
    "wf_features = [\n",
    "    'wf_count_1yr_ago',\n",
    "    'wf_count_2yr_ago',\n",
    "    'wf_count_3yr_ago',\n",
    "    'wf_count_4yr_ago',\n",
    "    'wf_count_5yr_ago'\n",
    "]\n",
    "\n",
    "sat_features = [\n",
    " 'sat_faparval_min',\n",
    " 'sat_faparval_max',\n",
    " 'sat_faparval_mean',\n",
    "#  'sat_faparval_median',\n",
    " 'sat_faparval_std',\n",
    " 'sat_faparval_size',\n",
    " 'sat_faparval_count',\n",
    " 'sat_faparval',\n",
    " 'sat_faparmask_min',\n",
    " 'sat_faparmask_max',\n",
    " 'sat_faparmask_mean',\n",
    "#  'sat_faparmask_median',\n",
    " 'sat_faparmask_std',\n",
    " 'sat_faparmask_size'\n",
    "]\n",
    "\n",
    "wea_features = [\n",
    " 'wea_air_temp_max',\n",
    " 'wea_air_temp_mean',\n",
    "#  'wea_precip_accum_max',\n",
    " 'relative_humidity_max',\n",
    " 'relative_humidity_min',\n",
    " 'relative_humidity_mean',\n",
    " 'wea_wind_speed_max',\n",
    " 'wea_wind_speed_min',\n",
    " 'wea_wind_speed_mean',\n",
    " 'wind_gust_max',\n",
    " 'wea_air_temp_mean_ma7',\n",
    "#  'wea_precip_accum_max_ma7',\n",
    " 'relative_humidity_mean_ma7',\n",
    " 'wea_air_temp_mean_l1',\n",
    "#  'wea_precip_accum_max_l1',\n",
    " 'relative_humidity_mean_l1'\n",
    "]\n",
    "\n",
    "new_features = [\n",
    " 'fuel_percent_ma7',\n",
    " 'fuel_percent_ma30',\n",
    " 'fuel_percent_l1',\n",
    " 'wea_air_temp_mean_ma30',\n",
    "#  'wea_precip_accum_max_ma30',\n",
    " 'relative_humidity_mean_ma30'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "feature_cols = wea_features + tl_features + sat_features + ['fuel_percent'] + new_features\n",
    "train, test, y_train, y_test, y_train_ext, y_test_ext, test_ids = split_train_test(final_df, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((825403, 33), (419090, 33))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "train_sc = scaler.fit_transform(train)\n",
    "test_sc = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53436386, 7.77508478])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw = class_weight.compute_class_weight('balanced', np.unique(y_train_ext), y_train_ext)\n",
    "cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'model_type': 'mlp',\n",
    "    'learning_rate': 1e-3,\n",
    "    'epochs': 20,\n",
    "    'batch_size': 128,\n",
    "    'layers': 2,\n",
    "    'units': 64,\n",
    "    'dropout_rate': 0.2,\n",
    "    'class_weights': {0: cw[0], 1: cw[1]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 825403 samples, validate on 419090 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      " - 10s - loss: 0.5746 - recall: 0.7459 - val_loss: 0.8415 - val_recall: 0.9362\n",
      "Epoch 2/20\n",
      " - 10s - loss: 0.5387 - recall: 0.7959 - val_loss: 0.7808 - val_recall: 0.9299\n",
      "Epoch 3/20\n",
      " - 10s - loss: 0.5270 - recall: 0.8041 - val_loss: 0.7684 - val_recall: 0.9102\n",
      "Epoch 4/20\n",
      " - 10s - loss: 0.5228 - recall: 0.8081 - val_loss: 0.6887 - val_recall: 0.8958\n",
      "Epoch 5/20\n",
      " - 9s - loss: 0.5185 - recall: 0.8111 - val_loss: 0.7532 - val_recall: 0.9167\n",
      "Epoch 6/20\n",
      " - 10s - loss: 0.5159 - recall: 0.8118 - val_loss: 0.6970 - val_recall: 0.8970\n",
      "Epoch 7/20\n",
      " - 10s - loss: 0.5144 - recall: 0.8142 - val_loss: 0.7006 - val_recall: 0.8938\n",
      "Epoch 8/20\n",
      " - 10s - loss: 0.5127 - recall: 0.8128 - val_loss: 0.6602 - val_recall: 0.8799\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.5113 - recall: 0.8148 - val_loss: 0.6506 - val_recall: 0.8782\n",
      "Epoch 10/20\n",
      " - 9s - loss: 0.5110 - recall: 0.8163 - val_loss: 0.7212 - val_recall: 0.9081\n",
      "Epoch 11/20\n",
      " - 10s - loss: 0.5096 - recall: 0.8188 - val_loss: 0.6983 - val_recall: 0.8857\n",
      "Epoch 12/20\n",
      " - 10s - loss: 0.5086 - recall: 0.8171 - val_loss: 0.6818 - val_recall: 0.8931\n",
      "Epoch 13/20\n",
      " - 9s - loss: 0.5075 - recall: 0.8170 - val_loss: 0.6407 - val_recall: 0.8630\n",
      "Epoch 14/20\n",
      " - 9s - loss: 0.5069 - recall: 0.8150 - val_loss: 0.6823 - val_recall: 0.8877\n",
      "Epoch 15/20\n",
      " - 10s - loss: 0.5068 - recall: 0.8197 - val_loss: 0.6571 - val_recall: 0.8866\n",
      "Epoch 16/20\n",
      " - 10s - loss: 0.5045 - recall: 0.8188 - val_loss: 0.6796 - val_recall: 0.8910\n",
      "Epoch 17/20\n",
      " - 9s - loss: 0.5041 - recall: 0.8189 - val_loss: 0.6675 - val_recall: 0.8817\n",
      "Epoch 18/20\n",
      " - 9s - loss: 0.5030 - recall: 0.8182 - val_loss: 0.6653 - val_recall: 0.9022\n",
      "Epoch 19/20\n",
      " - 9s - loss: 0.5041 - recall: 0.8151 - val_loss: 0.6692 - val_recall: 0.8879\n",
      "Epoch 20/20\n",
      " - 9s - loss: 0.5020 - recall: 0.8174 - val_loss: 0.6814 - val_recall: 0.8904\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "history, model_mlp, train_pred_probs, test_pred_probs = train_model((train_sc, y_train_ext, test_sc, y_test_ext), **model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp.save('./Models/mlp_adam_noprecip_cwEQ_ext.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Actual</th>\n",
       "      <th>Prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000215</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23303</td>\n",
       "      <td>0.050705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000818</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24456</td>\n",
       "      <td>0.151107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001800</td>\n",
       "      <td>56.0</td>\n",
       "      <td>31114</td>\n",
       "      <td>0.253315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001859</td>\n",
       "      <td>92.0</td>\n",
       "      <td>49478</td>\n",
       "      <td>0.353650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002919</td>\n",
       "      <td>215.0</td>\n",
       "      <td>73660</td>\n",
       "      <td>0.452401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003532</td>\n",
       "      <td>297.0</td>\n",
       "      <td>84093</td>\n",
       "      <td>0.550290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004403</td>\n",
       "      <td>338.0</td>\n",
       "      <td>76773</td>\n",
       "      <td>0.648132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003795</td>\n",
       "      <td>186.0</td>\n",
       "      <td>49018</td>\n",
       "      <td>0.741991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004638</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7115</td>\n",
       "      <td>0.822594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.946869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual                    Prob\n",
       "         mean    sum  count      mean\n",
       "Bin                                  \n",
       "1    0.000215    5.0  23303  0.050705\n",
       "2    0.000818   20.0  24456  0.151107\n",
       "3    0.001800   56.0  31114  0.253315\n",
       "4    0.001859   92.0  49478  0.353650\n",
       "5    0.002919  215.0  73660  0.452401\n",
       "6    0.003532  297.0  84093  0.550290\n",
       "7    0.004403  338.0  76773  0.648132\n",
       "8    0.003795  186.0  49018  0.741991\n",
       "9    0.004638   33.0   7115  0.822594\n",
       "10   0.000000    0.0     50  0.946869\n",
       "11   0.000000    0.0     30  1.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_prob(test_pred_probs[:,0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217079"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = test_pred_probs[:,0]>0.5\n",
    "test_preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[201623 216225]\n",
      " [   388    854]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         nwf       1.00      0.48      0.65    417848\n",
      "          wf       0.00      0.69      0.01      1242\n",
      "\n",
      "   micro avg       0.48      0.48      0.48    419090\n",
      "   macro avg       0.50      0.59      0.33    419090\n",
      "weighted avg       1.00      0.48      0.65    419090\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f33610b1438>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, test_preds, ['nwf', 'wf'], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer: Adam; Features: + precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_features = [\n",
    "    'tl_object_id',\n",
    "    'tl_kv_sort_sum'\n",
    "]\n",
    "\n",
    "wf_features = [\n",
    "    'wf_count_1yr_ago',\n",
    "    'wf_count_2yr_ago',\n",
    "    'wf_count_3yr_ago',\n",
    "    'wf_count_4yr_ago',\n",
    "    'wf_count_5yr_ago'\n",
    "]\n",
    "\n",
    "sat_features = [\n",
    " 'sat_faparval_min',\n",
    " 'sat_faparval_max',\n",
    " 'sat_faparval_mean',\n",
    "#  'sat_faparval_median',\n",
    " 'sat_faparval_std',\n",
    " 'sat_faparval_size',\n",
    " 'sat_faparval_count',\n",
    " 'sat_faparval',\n",
    " 'sat_faparmask_min',\n",
    " 'sat_faparmask_max',\n",
    " 'sat_faparmask_mean',\n",
    "#  'sat_faparmask_median',\n",
    " 'sat_faparmask_std',\n",
    " 'sat_faparmask_size'\n",
    "]\n",
    "\n",
    "wea_features = [\n",
    " 'wea_air_temp_max',\n",
    " 'wea_air_temp_mean',\n",
    " 'wea_precip_accum_max',\n",
    " 'relative_humidity_max',\n",
    " 'relative_humidity_min',\n",
    " 'relative_humidity_mean',\n",
    " 'wea_wind_speed_max',\n",
    " 'wea_wind_speed_min',\n",
    " 'wea_wind_speed_mean',\n",
    " 'wind_gust_max',\n",
    " 'wea_air_temp_mean_ma7',\n",
    " 'wea_precip_accum_max_ma7',\n",
    " 'relative_humidity_mean_ma7',\n",
    " 'wea_air_temp_mean_l1',\n",
    " 'wea_precip_accum_max_l1',\n",
    " 'relative_humidity_mean_l1'\n",
    "]\n",
    "\n",
    "new_features = [\n",
    " 'fuel_percent_ma7',\n",
    " 'fuel_percent_ma30',\n",
    " 'fuel_percent_l1',\n",
    " 'wea_air_temp_mean_ma30',\n",
    " 'wea_precip_accum_max_ma30',\n",
    " 'relative_humidity_mean_ma30'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "feature_cols = wea_features + tl_features + sat_features + ['fuel_percent'] + new_features\n",
    "train, test, y_train, y_test, y_train_ext, y_test_ext, test_ids = split_train_test(final_df, feature_cols)\n",
    "\n",
    "train_sc = scaler.fit_transform(train)\n",
    "test_sc = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'model_type': 'mlp',\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 20,\n",
    "    'batch_size': 128,\n",
    "    'layers': 2,\n",
    "    'units': 64,\n",
    "    'dropout_rate': 0.2,\n",
    "    'class_weights': {0: cw[0], 1: cw[1]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 825403 samples, validate on 419090 samples\n",
      "Epoch 1/20\n",
      " - 10s - loss: 0.5623 - recall_1: 0.7524 - val_loss: 0.7551 - val_recall_1: 0.9056\n",
      "Epoch 2/20\n",
      " - 10s - loss: 0.5092 - recall_1: 0.7984 - val_loss: 0.7254 - val_recall_1: 0.8727\n",
      "Epoch 3/20\n",
      " - 10s - loss: 0.4952 - recall_1: 0.7984 - val_loss: 0.6642 - val_recall_1: 0.8286\n",
      "Epoch 4/20\n",
      " - 10s - loss: 0.4883 - recall_1: 0.8021 - val_loss: 0.6874 - val_recall_1: 0.8491\n",
      "Epoch 5/20\n",
      " - 10s - loss: 0.4848 - recall_1: 0.8053 - val_loss: 0.6843 - val_recall_1: 0.8073\n",
      "Epoch 6/20\n",
      " - 10s - loss: 0.4815 - recall_1: 0.8064 - val_loss: 0.7052 - val_recall_1: 0.8091\n",
      "Epoch 7/20\n",
      " - 10s - loss: 0.4786 - recall_1: 0.8072 - val_loss: 0.7043 - val_recall_1: 0.8192\n",
      "Epoch 8/20\n",
      " - 10s - loss: 0.4763 - recall_1: 0.8094 - val_loss: 0.6349 - val_recall_1: 0.8205\n",
      "Epoch 9/20\n",
      " - 10s - loss: 0.4746 - recall_1: 0.8127 - val_loss: 0.6366 - val_recall_1: 0.8126\n",
      "Epoch 10/20\n",
      " - 10s - loss: 0.4741 - recall_1: 0.8118 - val_loss: 0.6539 - val_recall_1: 0.8109\n",
      "Epoch 11/20\n",
      " - 10s - loss: 0.4727 - recall_1: 0.8122 - val_loss: 0.6596 - val_recall_1: 0.8178\n",
      "Epoch 12/20\n",
      " - 10s - loss: 0.4709 - recall_1: 0.8150 - val_loss: 0.6401 - val_recall_1: 0.7970\n",
      "Epoch 13/20\n",
      " - 10s - loss: 0.4696 - recall_1: 0.8144 - val_loss: 0.6512 - val_recall_1: 0.8107\n",
      "Epoch 14/20\n",
      " - 10s - loss: 0.4695 - recall_1: 0.8152 - val_loss: 0.6293 - val_recall_1: 0.8209\n",
      "Epoch 15/20\n",
      " - 10s - loss: 0.4685 - recall_1: 0.8155 - val_loss: 0.5684 - val_recall_1: 0.7694\n",
      "Epoch 16/20\n",
      " - 10s - loss: 0.4668 - recall_1: 0.8165 - val_loss: 0.6483 - val_recall_1: 0.8275\n",
      "Epoch 17/20\n",
      " - 10s - loss: 0.4683 - recall_1: 0.8182 - val_loss: 0.6971 - val_recall_1: 0.8308\n",
      "Epoch 18/20\n",
      " - 10s - loss: 0.4675 - recall_1: 0.8165 - val_loss: 0.6593 - val_recall_1: 0.8461\n",
      "Epoch 19/20\n",
      " - 10s - loss: 0.4654 - recall_1: 0.8168 - val_loss: 0.6458 - val_recall_1: 0.8146\n",
      "Epoch 20/20\n",
      " - 10s - loss: 0.4669 - recall_1: 0.8144 - val_loss: 0.6443 - val_recall_1: 0.8341\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "history, model_mlp, train_pred_probs, test_pred_probs = train_model((train_sc, y_train_ext, test_sc, y_test_ext), **model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp.save('./Models/mlp_adam_precip_cwEQ_ext.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Actual</th>\n",
       "      <th>Prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000430</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30217</td>\n",
       "      <td>0.053640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000791</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37950</td>\n",
       "      <td>0.152313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001419</td>\n",
       "      <td>71.0</td>\n",
       "      <td>50039</td>\n",
       "      <td>0.251968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002112</td>\n",
       "      <td>122.0</td>\n",
       "      <td>57772</td>\n",
       "      <td>0.350540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004016</td>\n",
       "      <td>262.0</td>\n",
       "      <td>65235</td>\n",
       "      <td>0.450915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004729</td>\n",
       "      <td>299.0</td>\n",
       "      <td>63222</td>\n",
       "      <td>0.548956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004775</td>\n",
       "      <td>262.0</td>\n",
       "      <td>54864</td>\n",
       "      <td>0.646747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003553</td>\n",
       "      <td>127.0</td>\n",
       "      <td>35748</td>\n",
       "      <td>0.748075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002377</td>\n",
       "      <td>51.0</td>\n",
       "      <td>21457</td>\n",
       "      <td>0.840028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001952</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2561</td>\n",
       "      <td>0.923023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual                    Prob\n",
       "         mean    sum  count      mean\n",
       "Bin                                  \n",
       "1    0.000430   13.0  30217  0.053640\n",
       "2    0.000791   30.0  37950  0.152313\n",
       "3    0.001419   71.0  50039  0.251968\n",
       "4    0.002112  122.0  57772  0.350540\n",
       "5    0.004016  262.0  65235  0.450915\n",
       "6    0.004729  299.0  63222  0.548956\n",
       "7    0.004775  262.0  54864  0.646747\n",
       "8    0.003553  127.0  35748  0.748075\n",
       "9    0.002377   51.0  21457  0.840028\n",
       "10   0.001952    5.0   2561  0.923023\n",
       "11   0.000000    0.0     25  1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_prob(test_pred_probs[:,0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177877"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = test_pred_probs[:,0]>0.5\n",
    "test_preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[240715 177133]\n",
      " [   498    744]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         nwf       1.00      0.58      0.73    417848\n",
      "          wf       0.00      0.60      0.01      1242\n",
      "\n",
      "   micro avg       0.58      0.58      0.58    419090\n",
      "   macro avg       0.50      0.59      0.37    419090\n",
      "weighted avg       0.99      0.58      0.73    419090\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f33bc57fba8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, test_preds, ['nwf', 'wf'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
