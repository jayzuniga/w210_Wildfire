{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s2_py as s2\n",
    "import google.cloud.bigquery\n",
    "import pandas_gbq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shapefile as shp\n",
    "import geopandas as gpd\n",
    "import descartes\n",
    "from shapely.geometry import Polygon, mapping, Point\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "moisture_data_file = \"../data/FuelMoistureCA.xlsx\"\n",
    "moisture_sites_file = \"../data/FuelMoistureSites.xlsx\"\n",
    "cal_shape_file = \"..EDA/Data/CA_State/CA_State_TIGER2016.shp\"\n",
    "\n",
    "# ca_df = gpd.read_file(cal_shape_file)\n",
    "crs = {'init': 'epsg:4326'}\n",
    "# ca_df = ca_df.to_crs(crs)\n",
    "# ca_df.plot(color='white', edgecolor='lightgrey')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_S2_coverer(loop, lvl):\n",
    "    \"\"\"Generates a list of S2 Cells of specified level\"\"\"\n",
    "    coverer = s2.S2RegionCoverer()\n",
    "    coverer.set_min_level(lvl)\n",
    "    coverer.set_max_level(lvl)\n",
    "    return coverer.GetCovering(loop)\n",
    "\n",
    "def create_S2_loop(max_poly):\n",
    "    \"\"\"Converts Polygon into S2 Loop\"\"\"\n",
    "    points = []\n",
    "    for coord in tuple(reversed(max_poly)):\n",
    "        long, lat = coord\n",
    "        latlng = s2.S2LatLng.FromDegrees(lat, long)\n",
    "        points.append(latlng.ToPoint())\n",
    "    return s2.S2Loop(points)\n",
    "\n",
    "def extract_max_polygon(fire_poly):\n",
    "    \"\"\"Return the largest polygon for each wildfire multipolygon\"\"\"\n",
    "    fire_map = mapping(fire_poly)\n",
    "    if 'coordinates' in fire_map:\n",
    "        coords = fire_map['coordinates']\n",
    "    elif 'features' in fire_map:\n",
    "        coords = fire_map['features'][0]['geometry']['coordinates']\n",
    "    \n",
    "    max_poly = coords[0][0]\n",
    "    for i in range(len(coords)):\n",
    "        if len(coords[i][0]) > len(max_poly):\n",
    "            max_poly = coords[i][0]\n",
    "    return max_poly\n",
    "\n",
    "\n",
    "#todo possibly delete\n",
    "def S2Cells_To_GPD(covering):\n",
    "    geoms = []\n",
    "    for cellid in covering:\n",
    "        new_cell = s2.S2Cell(cellid)\n",
    "        vertices = []\n",
    "        for i in range(4):\n",
    "            vertex = new_cell.GetVertex(i)\n",
    "            latlng = s2.S2LatLng(vertex)\n",
    "            vertices.append((latlng.lng().degrees(),\n",
    "                             latlng.lat().degrees()))\n",
    "        geo = Polygon(vertices)\n",
    "        geoms.append(geo)\n",
    "    return gpd.GeoDataFrame(crs={'init': 'epsg:4326'}, geometry=geoms)\n",
    "\n",
    "\n",
    "\n",
    "def S2Cells_To_Poly(s2_cell):\n",
    "    geoms = []\n",
    "    new_cell = s2.S2Cell(s2_cell)\n",
    "    vertices = []\n",
    "    for i in range(4):\n",
    "        vertex = new_cell.GetVertex(i)\n",
    "        latlng = s2.S2LatLng(vertex)\n",
    "        vertices.append((latlng.lng().degrees(),\n",
    "                         latlng.lat().degrees()))\n",
    "    return Polygon(vertices)\n",
    "\n",
    "def split_data_frame_list(df, target_column, row_id):\n",
    "    \"\"\"\n",
    "    Splits a column with lists into rows\n",
    "    \n",
    "    Arguments:\n",
    "        df: dataframe\n",
    "        target_column: name of column that contains lists        \n",
    "        row_id: column to merge back on\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a new dataframe with each item in a seperate column, dropping rows with missing values\n",
    "    col_df = pd.DataFrame(df[target_column].tolist())\\\n",
    "                .join(df[[target_column, row_id]])\\\n",
    "                .drop(columns=[target_column])\\\n",
    "                .set_index(row_id)\n",
    "\n",
    "    # create a series with columns stacked as rows         \n",
    "    stacked = col_df.stack()\\\n",
    "                    .reset_index()\\\n",
    "                    .drop(columns='level_1')\n",
    "    stacked.columns = [row_id, target_column]\n",
    "\n",
    "    return stacked\n",
    "\n",
    "def closest_station(stations,s2_cells):\n",
    "    \"\"\"\n",
    "    Given an array of stations and an array of s2 cells identifies the nearest station to each s2 cell\n",
    "    \n",
    "    Args :\n",
    "        stations: pandas data frame with the following three columns:\n",
    "            site : station identifier\n",
    "            lng : longitude of the station\n",
    "            lat : lattitude of the station\n",
    "        s2_cells Pandas dataframe with the s2 cell centroids in column \"centroid\"\n",
    "    Returns : Pandas series \n",
    "    \n",
    "    \"\"\"\n",
    "    # array of x,y coords of each measurement station\n",
    "    X = stations[['lng','lat']].values\n",
    "    # array of x,y coords of each s2 cell\n",
    "    Y = np.array(s2_cells.geometry.apply(lambda x : np.array([x.x,x.y])))\n",
    "    # return nearest measurement station for each s2 cell\n",
    "    return stations.iloc[euclidean_distances(np.stack(X),np.stack(Y)).argmin(axis=0)].site.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we can extract only the largest polygon to build S2 Cells.\n",
    "# ca_df['Largest_polygon'] = ca_df.geometry.apply(extract_max_polygon)\n",
    "# ca_df.head()\n",
    "\n",
    "# # Now we can create an object called S2 loop based on that polygon's coordinates\n",
    "# ca_df['S2_Loop'] = ca_df.Largest_polygon.apply(create_S2_loop)\n",
    "\n",
    "# # args=[S2_Cell_Level]\n",
    "# ca_df['S2_Cells'] = ca_df.S2_Loop.apply(create_S2_coverer, args=[11])\n",
    "\n",
    "# #Give each s2 cell its own dataframe row\n",
    "# ca_s2_df = ca_df[['NAME', 'S2_Cells']]\n",
    "# ca_s2_df = split_data_frame_list(ca_s2_df, 'S2_Cells', 'NAME')\n",
    "# ca_s2_df['S2_Cells_ID'] = ca_s2_df.S2_Cells.apply(lambda x: x.ToToken())\n",
    "\n",
    "# # Create a column of shaply polygons for each cell\n",
    "# ca_s2_df['geometry'] = ca_s2_df.S2_Cells.apply(S2Cells_To_Poly)\n",
    "\n",
    "# #Get the centroid of each s2 cell\n",
    "# ca_s2_df['centroid'] = ca_s2_df.geometry.apply(lambda x : Point(x.centroid))\n",
    "# ca_s2_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring in the Fuel Moisture Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29415, 7)\n"
     ]
    }
   ],
   "source": [
    "moisture_data_df = pd.read_excel(moisture_data_file)\n",
    "moisture_data_df = moisture_data_df[moisture_data_df.Date > '2010-01-01']\n",
    "moisture_sites_df = pd.read_excel(moisture_sites_file)\n",
    "\n",
    "print(moisture_data_df.shape)\n",
    "moisture_data_df.set_index('Site',inplace=True,drop=True)\n",
    "\n",
    "# moisture_data = moisture_sites_df.join(moisture_data_df,'site',how='right')\n",
    "# Create Shapely Point objects from the lat lng\n",
    "moisture_sites_df['geometry'] = moisture_sites_df.apply(lambda x : Point(x['lng'],x['lat']),axis=1)\n",
    "# Convert to GeoPandas Df\n",
    "gdf = gpd.GeoDataFrame(moisture_sites_df, crs=crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the station closest to each s2 cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CWA</th>\n",
       "      <th>NAME</th>\n",
       "      <th>STATE_ZONE</th>\n",
       "      <th>FE_AREA</th>\n",
       "      <th>AREA</th>\n",
       "      <th>WF_cum_are</th>\n",
       "      <th>FZ_grp</th>\n",
       "      <th>S2_Cells_I</th>\n",
       "      <th>geometry</th>\n",
       "      <th>nearest_station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VEF</td>\n",
       "      <td>Death Valley National Park</td>\n",
       "      <td>CA227</td>\n",
       "      <td>ee</td>\n",
       "      <td>2.001602</td>\n",
       "      <td>37.487592</td>\n",
       "      <td>low</td>\n",
       "      <td>80b8a4</td>\n",
       "      <td>POINT (-116.8910062173898 36.87155245914239)</td>\n",
       "      <td>Cedar Grove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VEF</td>\n",
       "      <td>Death Valley National Park</td>\n",
       "      <td>CA227</td>\n",
       "      <td>ee</td>\n",
       "      <td>2.001602</td>\n",
       "      <td>37.487592</td>\n",
       "      <td>low</td>\n",
       "      <td>80b8ac</td>\n",
       "      <td>POINT (-117.0793794721554 36.82552116397655)</td>\n",
       "      <td>Cedar Grove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VEF</td>\n",
       "      <td>Death Valley National Park</td>\n",
       "      <td>CA227</td>\n",
       "      <td>ee</td>\n",
       "      <td>2.001602</td>\n",
       "      <td>37.487592</td>\n",
       "      <td>low</td>\n",
       "      <td>80b8b4</td>\n",
       "      <td>POINT (-117.0793796132071 36.98512533455602)</td>\n",
       "      <td>Cedar Grove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEF</td>\n",
       "      <td>Death Valley National Park</td>\n",
       "      <td>CA227</td>\n",
       "      <td>ee</td>\n",
       "      <td>2.001602</td>\n",
       "      <td>37.487592</td>\n",
       "      <td>low</td>\n",
       "      <td>80be44</td>\n",
       "      <td>POINT (-118.2058442001594 37.3352638859018)</td>\n",
       "      <td>Cedar Grove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VEF</td>\n",
       "      <td>Death Valley National Park</td>\n",
       "      <td>CA227</td>\n",
       "      <td>ee</td>\n",
       "      <td>2.001602</td>\n",
       "      <td>37.487592</td>\n",
       "      <td>low</td>\n",
       "      <td>80be4c</td>\n",
       "      <td>POINT (-118.20584405509 37.17744937398349)</td>\n",
       "      <td>Cedar Grove</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CWA                        NAME STATE_ZONE FE_AREA      AREA  WF_cum_are  \\\n",
       "0  VEF  Death Valley National Park      CA227      ee  2.001602   37.487592   \n",
       "1  VEF  Death Valley National Park      CA227      ee  2.001602   37.487592   \n",
       "2  VEF  Death Valley National Park      CA227      ee  2.001602   37.487592   \n",
       "3  VEF  Death Valley National Park      CA227      ee  2.001602   37.487592   \n",
       "4  VEF  Death Valley National Park      CA227      ee  2.001602   37.487592   \n",
       "\n",
       "  FZ_grp S2_Cells_I                                      geometry  \\\n",
       "0    low     80b8a4  POINT (-116.8910062173898 36.87155245914239)   \n",
       "1    low     80b8ac  POINT (-117.0793794721554 36.82552116397655)   \n",
       "2    low     80b8b4  POINT (-117.0793796132071 36.98512533455602)   \n",
       "3    low     80be44   POINT (-118.2058442001594 37.3352638859018)   \n",
       "4    low     80be4c    POINT (-118.20584405509 37.17744937398349)   \n",
       "\n",
       "  nearest_station  \n",
       "0     Cedar Grove  \n",
       "1     Cedar Grove  \n",
       "2     Cedar Grove  \n",
       "3     Cedar Grove  \n",
       "4     Cedar Grove  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_s2_df = gpd.read_file('../DataPrep/Data/Processed/CA_S2Cells/CA_S2Cells_centroids.shp')\n",
    "ca_s2_df.shape\n",
    "ca_s2_df['nearest_station'] = closest_station(moisture_sites_df,ca_s2_df)\n",
    "ca_s2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joins temporal moisture data to geospatial s2 data \n",
    "moisture_dataset = ca_s2_df.merge(\n",
    "    moisture_data_df,\n",
    "    how='outer',\n",
    "    left_on=\"nearest_station\",\n",
    "    right_on = 'Site')\n",
    "\n",
    "moisture_dataset['uid'] = moisture_dataset['S2_Cells_I'] + moisture_dataset['Date'].astype(str)\n",
    "moisture_dataset.drop_duplicates(inplace=True,subset=['Date','S2_Cells_I'])\n",
    "moisture_dataset.sort_values(by=['Date','nearest_station'],inplace=True)\n",
    "moisture_dataset['Percent'] = moisture_dataset.Percent.interpolate('nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Data Sets and write to GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096,)\n",
      "        Date S2_Cells_I               uid\n",
      "0 2016-01-01     80b8a4  80b8a42016-01-01\n",
      "1 2016-01-01     80b8ac  80b8ac2016-01-01\n",
      "2 2016-01-01     80b8b4  80b8b42016-01-01\n",
      "3 2016-01-01     80be44  80be442016-01-01\n",
      "4 2016-01-01     80be4c  80be4c2016-01-01\n"
     ]
    }
   ],
   "source": [
    "# Date range index\n",
    "ix = pd.date_range('2016-01-01','2018-12-31')\n",
    "iterables = [ix,ca_s2_df['S2_Cells_I'].unique()]\n",
    "print(ix.shape)\n",
    "# Cartesian product of S2 cells and dates aka one row for every cell/date combo\n",
    "full_df = pd.MultiIndex.from_product(iterables, names=['Date','S2_Cells_I']).to_frame()\n",
    "full_df['uid'] = full_df['S2_Cells_I'] + full_df['Date'].astype(str)\n",
    "full_df.reset_index(inplace=True,drop=True)\n",
    "print(full_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date S2_Cells_I                uid Percent\n",
      "539  2016-01-01     54c934   2016-01-0154c934      59\n",
      "7814 2016-01-01    54c9354  2016-01-0154c9354      65\n",
      "7815 2016-01-01    54c935c  2016-01-0154c935c      65\n",
      "7816 2016-01-01    54c9364  2016-01-0154c9364      65\n",
      "7817 2016-01-01    54c9414  2016-01-0154c9414      65\n",
      "(11664728, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:23, 83.28s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# full_df1 = full_df.merge(moisture_dataset[['S2_Cells_I','uid','Percent','Date']],\n",
    "#                         left_on='uid',\n",
    "#                         right_on='uid',\n",
    "#                         how='left')\n",
    "\n",
    "# full_df1.drop(['S2_Cells_I_y','Date_y'],axis=1,inplace=True)\n",
    "# full_df1.columns = ['Date','S2_Cells_I','uid','Percent']\n",
    "full_df1.sort_values(inplace=True,by='uid')\n",
    "full_df1['Percent'] = full_df1.Percent.interpolate(method='nearest').fillna('backfill')\n",
    "# full_df1.fillna()\n",
    "print(full_df1.head())\n",
    "print(full_df1.shape)\n",
    "\n",
    "#Write the results to GCP\n",
    "full_df1.to_gbq('fuel_moisture_by_s2_cell.fuel_moisture',\n",
    "                        'neon-obelisk-215514',\n",
    "                       if_exists='replace',\n",
    "                       reauth=True)\n",
    "\n",
    "# moisture_dataset.shape\n",
    "#Write the results to GCP\n",
    "# moisture_data_df.to_gbq('fuel_moisture_by_s2_cell.fuel_moisture_data',\n",
    "#                         'neon-obelisk-215514',\n",
    "#                        if_exists='replace',\n",
    "#                        reauth=True)\n",
    "\n",
    "# Seems to be an encoding issues with the S2_Cells col\n",
    "# ca_s2_df.drop(['S2_Cells'],axis=1,inplace=True)\n",
    "# ca_s2_df.to_gbq('fuel_moisture_by_s2_cell.s2_cells',\n",
    "#                 'neon-obelisk-215514',\n",
    "#                 if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df1[full_df1.Percent.isna()].shape\n",
    "# moisture_dataset.reindex(ix, method='nearest')\n",
    "# moisture_dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
